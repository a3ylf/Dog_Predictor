{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv(\"input.csv\", delimiter=\",\")\n",
    "df = df.drop(columns=[\"name\",\"description\",\"temperament\"]) # Retira-se nome, descrição e temperamento, pois são irrelevantes para o processamento\n",
    "\n",
    "# Uma breve pesquisa sobre as raças mostra que estão na classe \"Miscellaneous Class\" estão contidos nos do grupo \"Foundation Stock Service\", porém \n",
    "# esperam reconhecimento de uma organização, então decidi agrupa-los em um grupo só\n",
    "df[\"group\"] = df[\"group\"].replace([\"Foundation Stock Service\",\"Miscellaneous Class\"],\"Foundation and miscellaneous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ao ler os dados, é notavel que os valores para: grooming_frequency, shedding, energy_level, trainability e demeanor são equivalentes a sua categoria, logo, pode-se ignorar todas as colunas que terminem com \"category\" visto que são dados redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"grooming_frequency_category\",\"shedding_category\",\"energy_level_category\",\"trainability_category\",\"demeanor_category\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Devido a quase 30% dos dados estarem sem o atributo \"popularity\" decidi por não incluir esse atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"popularity\"] = pd.to_numeric(df[\"popularity\"], errors=\"coerce\")\n",
    "median = df[\"popularity\"].median(skipna=True)\n",
    "df[\"popularity\"] = df[\"popularity\"].fillna(median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le = preprocessing.LabelEncoder() #transforma atributo 'group' em número\n",
    "#df[\"group\"] = le.fit_transform(df[\"group\"])\n",
    "#df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotagem do gráfico de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= df.drop(columns=\"group\").corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pelo gráfico de correlação, é notável que há uma correlação entre min e max height e weight, assim como min e max expectancy. Irei agrupa-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size define a junção das médias das alturas com a média dos pesos\n",
    "\n",
    "df[\"size\"] = (df[\"min_height\"] + df[\"max_height\"])/2 + (df[\"min_weight\"] + df[\"max_weight\"])/2\n",
    "df[\"avg_expectancy\"] = (df[\"min_expectancy\"] + df[\"max_expectancy\"])/2\n",
    "df = df.drop(columns=[\"min_height\",\"min_weight\",\"min_expectancy\",\"max_height\",\"max_weight\",\"max_expectancy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(columns=\"group\").corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com os agrupamentos feitos, os atributos tem pouquissima correlação entre si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Valores faltantes:\\n', df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No conjunto de dados, muitos dos dados que possuem atributos faltantes, possuem mais de um atributo faltante, e apesar de ter quase 90 atributos faltantes\n",
    "# Apenas 41 Valores serão perdidos com o expurgo total dos dados incompletos\n",
    "df[\"trainability_value\"] = pd.to_numeric(df[\"trainability_value\"], errors=\"coerce\")\n",
    "median = df[\"trainability_value\"].median(skipna=True)\n",
    "df[\"trainability_value\"] = df[\"trainability_value\"].fillna(median)\n",
    "\n",
    "df[\"demeanor_value\"] = pd.to_numeric(df[\"demeanor_value\"], errors=\"coerce\")\n",
    "median = df[\"demeanor_value\"].median(skipna=True)\n",
    "df[\"demeanor_value\"] = df[\"demeanor_value\"].fillna(median)\n",
    "\n",
    "df[\"shedding_value\"] = pd.to_numeric(df[\"shedding_value\"], errors=\"coerce\")\n",
    "median = df[\"shedding_value\"].median(skipna=True)\n",
    "df[\"shedding_value\"] = df[\"shedding_value\"].fillna(median)\n",
    "\n",
    "#print('Valores faltantes:\\n', df.isnull().sum())\n",
    "\n",
    "df = df.dropna(how ='any') #elimina todas as linhas com dados ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decido plotar o gráfico de cada um para buscar valores que não fazem sentido, para garantir a qualidade dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    plt.figure()\n",
    "    plt.plot(df.index, df[column], marker='o', linestyle='None')\n",
    "    plt.title(column)\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para a coluna 'energy_value' há apenas um com o valor 0.2, porém aparentemente é um outlier, visto que tem uma categoria só para ele, chamada 'couch potato', então não irei o retirar. É perceptivel também, que para o 'grupo 3', há uma menor quantidade de dados, portanto, irei aplicar o boosting. É notavel também que o atributo \"avg_expectancy\" quase não tem variação, então irei retira-lo, pois não agrega em nada para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"avg_expectancy\")\n",
    "#df = df.drop(columns=\"size\")\n",
    "# Selecionar todos os dados do grupo 3\n",
    "demeanor_02_data = df[df[\"demeanor_value\"] == 0.2]\n",
    "demeanor_1_data = df[df[\"demeanor_value\"] == 1]\n",
    "grooming_1_data = df[df[\"grooming_frequency_value\"] == 1]\n",
    "shedding_1_data = df[df[\"shedding_value\"] == 1.0 ]\n",
    "shedding_08_data = df[df[\"shedding_value\"] == 0.8 ]\n",
    "energy_04_data = df[df[\"energy_level_value\"] == 0.4]\n",
    "group_3_data = df[df['group'] == 3]\n",
    "# Duplicar os dados do grupo 3\n",
    "df = pd.concat([df, group_3_data], ignore_index=True)\n",
    "df = pd.concat([df, grooming_1_data], ignore_index=True)\n",
    "df = pd.concat([df, demeanor_02_data], ignore_index=True)\n",
    "df = pd.concat([df, demeanor_1_data], ignore_index=True)\n",
    "df = pd.concat([df, shedding_1_data], ignore_index=True)\n",
    "df = pd.concat([df, shedding_08_data], ignore_index=True)\n",
    "df = pd.concat([df, energy_04_data], ignore_index=True)\n",
    "\n",
    "\n",
    "df[\"group\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Excluir a coluna 'group' antes de normalizar\n",
    "df_without_group = df.drop('group', axis=1)\n",
    "\n",
    "# Criar um objeto MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizar os dados usando MinMaxScaler\n",
    "df_normalized = min_max_scaler.fit_transform(df_without_group)\n",
    "\n",
    "# Criar um novo DataFrame com os dados normalizados\n",
    "df_normalized = pd.DataFrame(df_normalized, columns=df_without_group.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.to_csv(\"Processed_data.csv\",index=False)\n",
    "df[\"group\"].to_csv(\"grupos.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
